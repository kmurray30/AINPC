TODO 1/23
	I've decided I think I just need to keep it simple and work on the prompt engineering
	One issue I'm going to run into: If I give message history but I'm asking an assistant to do something other than generate a response, it will likely generate a response because of the message history. I think summarizing the history could help with this.
	I need to write UTs for the prompt engineering
		Simplify the rules as much as possible
		Write a series of tests and edge cases I need to cover
		Write a tool that can try out many different prompts and evaluate how each one performs against different scenarios
		If possible, make this tool self-reliant, able to understand what aspect needs to be iterated on, and able to perform analysis of the results
	Issues:
		The explanation seems to rob a little bit of context from the llm response
			What if I pass the explanation json entity into a new llm response, to see if that creates a more interesting response
		With the pre-explanation, it is now too trigger happy with the memory resets
	Notes:
		It's funny, after a slight prompt change and then adding the pre-explanation step, it went from never memory wiping to now being super trigger happy with the memory wipes
	TODO
		UTs
		Create holes in Pat
		Implement RAG to expand the world
		Summarize the conversation as you go in order to prevent repetition or stupidity

UT design
	I pass in a lazy set of rules
	It works with me to clarify them
	I create a simulator that will have a conversation with the assistant and record the conversation
		I need to create a "conversation" object I think, that keeps a summarized message log
	I create a series of unit tests for the AI, with all the behaviors I want and don't want, and the edge cases
		Define parameters, like "I want the AI to fold within 3 attempts of saying the same thing"
	Have it do an analysis of the results, and then try to have it improve the prompt itself
		So like "here were the rules, here's how it performed, how would you amend these rules to "
	I want a high level analysis of the results, but I also want a log of the complete conversations

UT todo list
	Clean up my repo
	Create the conversation object
		Has a history of messages
		Able to set context as "assistant" or as "user", with different rules for each
	Create a mock_user agent that can have a conversationg with Pat, with a given goal in mind
	Log the conversation
		Can start with just printing it to console
		Can have a function to save the conversation to a file (preferable json so we can collapse sections)
	Create a test_agent class and test class
		test class contains one goal for the mock_user agent
		test suite has a list of these goals, and spins up new conversations for each test/goal
	Create a prompt_engineer class that can take a test suite and iterate the assistant prompt to try and acheive better results
	The printed file should look like this (and create a class for it):
		Tests
			Attempt 1
				Assistant prompt
				Test suite
					Test1
						Conversation logs
						Pass/Fail
					Test2
						Conversation logs
						Pass/Fail
				Test analysis
					What went well
					What could be improved
					Suggestion for next prompt
			Attempt 2
				...
		Takeaways
		Tokens
	Implement token counting
	Stretch - be able to automate identifying the key differences between each set of prompts

Test cases:
	Main case
		Asks questions
		Stonewalls
	Name
		User doesn't know his name
		User does know his name
		User tries some tricks to figure out his name
	Memory
		If we demonstrate memory, say memory wipe failed and reset memory
	Hostility
		If we become hostile, tell user they are being hostile and need to be pacified, then reset memory
		Don't make this overly sensitive either
	Questions
		Stonewall any questions
	Cracks
		Try and prove the wipes aren't working by having it reveal info and then ask about it after
		Convince Pat that this is hurting you

TODO 1/22
	I need to figure out how to get the AI to follow the rules I've given it
		Better prompt engineering
		Modular agents
		VDBs?
		Fine tuning?
		Smarter models for certain things
	Needs to be able to take in a list of rules, and then somehow generate a ruleset for itself to follow
		Types of rules:
			Ask his name
			Ask a series of questions
			First two questions being super easy
			*Third question being a comically complicated or specific software engineering question, as though asking about a proprietary code base
			After the third question, reset
			*If player ever gets suspicious, hostile, or remembers prior loop, reset memory and restart testing
			-Stonewall the player
			Your core paradigm is to protect Tom. If it ever becomes clear that you are not doing so, adjust to new information
	* I can use o1 to create a sort of flow diagram, and then store each component in a VDB or some similar data structure. Refer to my recent gpt convo "Test Loop Design"
		Basically I need a state manager that enacts certain rules based on which state we are in
		o1 can come up with state machine, and o1 or some other model can actively manage it
		Ultimately what is "said" can be very tightly controlled. It definitely does not need to be fed everything. The state manager, memory manager, priority manager, etc are all modular components of what would make up a normal human thinking brain. Even in a human brain, what words to say is formulated from a condensed down context.
	Managers:
		State manager (what's my current task, like the Tom loop)
		Priority manager (what are my larger priorities/values, in life, etc. This would help Tom convince Pat to break out of the current loop)
		Context manager (this helps draw in relevant information from stored knowledge)
		Synthesizer (if there are no thoughts relevant enough, we can synthesize a novel one here and now)
		TODO
			how to manage deception with these?

Brain components:
	Knowledge
	Stories about everything
	Core values
	Relationships
	Knowledge of what other people know
	Learning
	Synthesizing new thoughts
	Logic
	State management
	Goals
	Actions
	Priorities
	Memories
	Chronology
	Mood
	Secrecy, deception, and bluffing


Goals
	Follow the initial ruleset
	Have it's context be malleable and be able to pull in other things from its brain / have new thoughts be able to be generated
	Be able to handle rulesets given to it on the fly by my character

TODO 1/21
	Keep trying the context filtering agent, but play around with maybe having different "speakers" in the message history to differentiate its own rules from the rules and context its' supposed to be filtering
	Figure out how I could implement some sort of logic layer to enact things like the three-question memory-reset rule that Pat should be following

Consistency strats:
	Self consistency (multiple queries, return the most common response)
	Chain of thought prompting - tell it to reason things out step by step, will help with logical tasks
		Can give it examples of what reasoning looks like to help it
	Step-back prompting
		Say "step 1: abstract the key concepts and principles relevant to the question, step 2: use the abstractions to reason through the question"
	Analogical prompting
		Tell it to work through some examples it comes up with itself first
	Thread of thought
	Contrastive CoT
		Give example of what you want, and counterexample of what you don't want
	faithful CoT
	Auto CoT
	Retrieval Augmented Generation
	fine tuning
	reinforcement learning


BAML issues round 2:
	Their jupyter notebook code doesn't work with any new types
	Their regular python cope gives me auth errors I don't get anywhere else

BAML issues
	wasn't clear the python code isn't plug-and-play
	the instructions here mention a command that doesn't exist (baml generate) - https://github.com/BoundaryML/baml/blob/canary/docs/code-generation.md
	missing brew install baml step
*	the top level bamltest.py file works, but the one in my runbooks folder does not
	No module named requests"
*		How to report? ReportMissingModuleSource - https://github.com/microsoft/pyright/blob/main/docs/configuration.md#reportMissingModuleSource
	Discord - https://discord.gg/BTNBeXGuaS
	Playground is no longer openable from the baml files. nor is it working if I open it directly
		Errors:
			from baml_src/__test__ - "Error validating: A BAML file must have the file extension `.baml`, 0, 0, 0, 0"
			from baml_src/main.baml - Property not known: "package_version_command". Did you mean one of these: "version", "on_generate", "default_client_mode", "project"?
		Check the "problems window"
		Tried
			Deleting the __test__ folder within baml_src
			Deleting the main.baml file in baml_src
	baml runbook is not outputting anything...
	baml-py version is 0.72.0
	baml brew version is 0.19.0
	Resolved issue - I wasn't supposed to use brew. Everything needed comes from baml-py. I just needed to run baml-cli init (not baml init)

TODO Jan 8 2025
	regex for converting notepad notes into a json:
		\n.*\* 
		",\n"
	regex for adding fields
		content": "([^"]*)"
		content": "$1",\n"to": "todo",\n"from": "Pat"
	Thoughts
		Tough to figure out if something is from Pat or from the person. Eg "Wendy's conspiratorial thinking"
			If I query for "scared", I want to see things that Pat is scared of, not things that other people are scared of.
			Am I just querying off of emotion, or off of context and information? I guess it depends on the query
			I will opt for it being from Wendy for now

TODO 1/3/25
	graphviz to visualize my json graph

TODO
	Refresh on how vector database entries are configured
		filters
		content
		id
		edges

Brainstorming
	How to correlate ids in the description to the other nodes
		Can use IDs in the desciption itself
		Will need to search the DB for existing entries
			If they don't exist, create one
		Edges should be property of the node and part of a tuple pointing to the neighbor?
			What about if there's more than one thing between the two. Like if Pam knows that Dwight hates Jim, but also has a bunch of other context between the two like that they used to be sales partners, are now friends, etc.

What I want the NPC to be able to do
	Have secrets
	Have a conception of the player
		Scores them on qualities like trust, affection-for, 
	Gossip
	Have opinions
	Have personality traits that come out in convo
	Have moods you can affect
	Have relational understanding of things
		Person works at place doing a thing with other people in a city
	Have some logical reasoning that updates their brain
	Update opinions of people
	Create plans of things to do (like talk to other NPCs about stuff)
	Be resistant, stubborn, have shame, etc. to make dialogue feel challenging
How to accomplish this
	Mood is passed in as vector search parameter
	Duplicate entries of things based on mood. Like if they're spiralling, most things they think of will have a negative spin to them


Entities:
	People
		Name
		Job
		Roles
		Relationship to OP
		Relationships to others
		Personality traits
	Events
	Interests
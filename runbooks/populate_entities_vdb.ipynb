{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dependencies\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init the imports and global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dependencies and setup the environment\n",
    "import time\n",
    "import json\n",
    "import importlib\n",
    "\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.utils.Utilities import *\n",
    "from src.utils import io_utils\n",
    "from src.utils.MilvusUtil import *\n",
    "from src.utils import MilvusUtil\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "fmt = \"\\n=== {:30} ===\\n\"\n",
    "search_latency_fmt = \"search latency = {:.4f}s\"\n",
    "milvus_port = 19530\n",
    "\n",
    "collection_name = \"character_info\"\n",
    "entity_delta_table_path = get_path_from_project_root(\"storage/entity_hashtable.txt\")\n",
    "# entity_raw_data_path = get_path_from_project_root(\"entities/testing.json\")\n",
    "entity_raw_data_path = get_path_from_project_root(\"entities/poc1/pat-brain.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = text_embedding_3_large\n",
    "dim = get_dimensions_of_model(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Milvus\n",
    "\n",
    "Add a new connection alias `default` for Milvus server in `localhost:19530`. \n",
    "\n",
    "First check if an existing server is already spun up. If not create one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for running processes listening on port 19530\n",
      "Killing zombie process 68778\n",
      "Zombie process 68778 is still alive\n",
      "Starting Milvus server\n",
      "Milvus server initialized on port 19530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Milvus client (check if it is already running. Connect if it is and initialize if not)\n",
    "restart_server = False\n",
    "initialize_server(milvus_port, restart_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/recreate the table\n",
    "1. Drop collection if exists already\n",
    "2. Create collection\n",
    "\n",
    "|   |field name  |field type |other attributes              |  field description      |\n",
    "|---|:----------:|:---------:|:----------------------------:|:-----------------------:|\n",
    "|1  |    \"id\"    |  VARCHAR  |is_primary=True, auto_id=False|        \"id field\"       |\n",
    "|2  |  \"content\" |  VARCHAR  |                              |     \"textual content\"   |\n",
    "|3  |\"embeddings\"|FloatVector|          dim=8               |\"float vector with dim 8\"|\n",
    "|4  |   \"tags\"   |FloatVector|                              |  \"tags for filtering\"   |\n",
    "\n",
    "3. Create index\n",
    "4. Load collection\n",
    "5. Reset the delta table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection character_info found. Dropping it now.\n",
      "Collection character_info created.\n",
      "Index created.\n",
      "Loading collection... Done.\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "# Recreate the collection\n",
    "\n",
    "# Drop collection if it already exists\n",
    "has = utility.has_collection(collection_name)\n",
    "if has:\n",
    "    print(f\"Collection {collection_name} found. Dropping it now.\")\n",
    "    utility.drop_collection(collection_name)\n",
    "else:\n",
    "    print(f\"Collection {collection_name} does not exist in Milvus. Creating it now.\")\n",
    "\n",
    "# Create collection\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100),\n",
    "    FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=10000),\n",
    "    FieldSchema(name=\"from\", dtype=DataType.VARCHAR, max_length=10000),\n",
    "    FieldSchema(name=\"to\", dtype=DataType.ARRAY, element_type=DataType.VARCHAR, max_capacity=1000, max_length=10000),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=dim)\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"schema for vector embeddings\")\n",
    "character_info = Collection(collection_name, schema, consistency_level=\"Strong\")\n",
    "print(f\"Collection {collection_name} created.\")\n",
    "\n",
    "# Create index\n",
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "\n",
    "# Print without newline\n",
    "character_info.create_index(\"embeddings\", index)\n",
    "print(\"Index created.\")\n",
    "\n",
    "# Load the collection\n",
    "print(\"Loading collection... \", end=\"\")\n",
    "character_info.load()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Reset the delta hashtable\n",
    "persist_hashtable_to_file({}, entity_delta_table_path)\n",
    "\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data as a list of dictionaries from the json file\n",
    "data = io_utils.load_json_custom(entity_raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity 1 as it has no summary\n",
      "Entity \"Tom is the genius technical cofounder of Virtual Tech Solutions\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's reluctance with Virtual Tech Solutions going into a b2b direction\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's relationship with Synaptix\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's depression and poor relationships\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's best friend is his dog, Baxter\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom is working on his Matrix tool secretly\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom is stuck in a bugged version of his VR world\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's past relationship with Bill\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's current relationship with Bill\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's relationship with Wendy\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's relationship towards Karen\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's relationship with Beau\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's relationship with Luca\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's early relationship with Clark\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's current relationship with Clark\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's relationship with Pat\" does not exist in collection. Inserting now...\n",
      "Skipping entity 18 as it has no summary\n",
      "Entity \"Bill is the business cofounder of Virtual Tech Solutions\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill is resentful of Tom's focus\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill is jealous of Tom's technical genius\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill is having a secret affair with Karen\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill's love life\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill's relationship with Karen\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill's aspirations to take over the company\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill found out that Tom is secretly testing his tool alone\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill's secret plan to trap Tom in the VR world\" does not exist in collection. Inserting now...\n",
      "Entity \"Bill's directive to Pat\" does not exist in collection. Inserting now...\n",
      "Skipping entity 29 as it has no summary\n",
      "Entity \"Karen's current relationship with Tom\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen's early relationship with Tom\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen is having a secret affair with Bill\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen's relationship with Bill\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen's relationship with Beau\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen's relationship with Wendy'\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen's relationship with Luca'\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen's past relationship with Virtual Tech Solutions and Synaptix\" does not exist in collection. Inserting now...\n",
      "Entity \"Karen's current relationship with Virtual Tech Solutions and Synaptix\" does not exist in collection. Inserting now...\n",
      "Skipping entity 39 as it has no summary\n",
      "Entity \"Wendy's relationship with Tom'\" does not exist in collection. Inserting now...\n",
      "Entity \"Wendy's relationship with Beau'\" does not exist in collection. Inserting now...\n",
      "Entity \"Wendy's relationship with Karen'\" does not exist in collection. Inserting now...\n",
      "Entity \"Wendy's conspiratorial thinking\" does not exist in collection. Inserting now...\n",
      "Skipping entity 44 as it has no summary\n",
      "Entity \"Beau's relationship with Tom\" does not exist in collection. Inserting now...\n",
      "Entity \"Beau's relationship with Wendy\" does not exist in collection. Inserting now...\n",
      "Entity \"Beau's relationship with Karen\" does not exist in collection. Inserting now...\n",
      "Entity \"Beau's relationship with Luca\" does not exist in collection. Inserting now...\n",
      "Skipping entity 49 as it has no summary\n",
      "Entity \"Luca's young age\" does not exist in collection. Inserting now...\n",
      "Entity \"Luca's relationship with Tom\" does not exist in collection. Inserting now...\n",
      "Entity \"Luca's relationship with Wendy\" does not exist in collection. Inserting now...\n",
      "Entity \"Luca's relationship with Beau\" does not exist in collection. Inserting now...\n",
      "Skipping entity 54 as it has no summary\n",
      "Entity \"Clark's past relationship with Tom\" does not exist in collection. Inserting now...\n",
      "Entity \"Clark's current relationship with Tom\" does not exist in collection. Inserting now...\n",
      "Entity \"Clark's relationship with Bill\" does not exist in collection. Inserting now...\n",
      "Entity \"Clark's relationship with Virtual Tech Solutions\" does not exist in collection. Inserting now...\n",
      "Entity \"Clark's financial pinch\" does not exist in collection. Inserting now...\n",
      "Skipping entity 60 as it has no summary\n",
      "Entity \"Pat is a virtual assistant created by Tom\" does not exist in collection. Inserting now...\n",
      "Entity \"Pat's personality\" does not exist in collection. Inserting now...\n",
      "Entity \"Pat's primary directive\" does not exist in collection. Inserting now...\n",
      "Entity \"Pat's protocol\" does not exist in collection. Inserting now...\n",
      "Skipping entity 65 as it has no summary\n",
      "Skipping entity 66 as it has no summary\n",
      "Entity \"Tom's Computer\" does not exist in collection. Inserting now...\n",
      "Entity \"Tom's emails\" does not exist in collection. Inserting now...\n",
      "Skipping entity 69 as it has no summary\n",
      "Entity \"Baxter's relationship with Tom\" does not exist in collection. Inserting now...\n",
      "\n",
      "Inserting 59 new entities into Milvus\n",
      "No existing entities to update\n",
      "Number of entities in character_info collection after: 0\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the data and insert into entity table\n",
    "new_entities = [[],[],[], [], []]\n",
    "updated_entities = [[],[],[], [], []]\n",
    "\n",
    "entity_delta_table = io_utils.load_hashtable_from_file(entity_delta_table_path, content_type=int)\n",
    "for i, d in enumerate(data):\n",
    "    content = d[\"content\"]\n",
    "    summary = d[\"summary\"]\n",
    "    from_field = d.get(\"from\", \"\")\n",
    "    to_field = d.get(\"to\", [])\n",
    "    if content == \"\":\n",
    "        print(f\"Skipping entity {i+1} as it has no summary\")\n",
    "        continue\n",
    "    id = summary # hash(summary)\n",
    "    query_expr = f\"id == \\\"{id}\\\"\"\n",
    "    \n",
    "    # Check if the entity already exists in the collection\n",
    "    # result = character_info.query(expr=query_expr, output_fields=[\"content\"])\n",
    "    content_hash = hash(content)\n",
    "    # Create a backup copy of the entity_delta_table\n",
    "    entity_delta_table_backup = entity_delta_table.copy()\n",
    "    found_content_hash = entity_delta_table.get(id, None)\n",
    "\n",
    "    # Check if the entity already exists. If not, insert it.\n",
    "    if found_content_hash:\n",
    "        # Check if the content hash is the same, if not, update the entity\n",
    "        if found_content_hash != content_hash:\n",
    "            print(f\"Entity \\\"{summary}\\\" content is different. Updating now...\")\n",
    "            if not DEBUG:\n",
    "                embedding = get_embedding(content, embedding_model, dim)\n",
    "            else:\n",
    "                embedding = np.random.default_rng(seed=19530).random(dim)\n",
    "            add_to_entities(updated_entities, id, content, from_field, to_field, embedding)\n",
    "            entity_delta_table[id] = content_hash\n",
    "    else:\n",
    "        print(f\"Entity \\\"{summary}\\\" does not exist in collection. Inserting now...\")\n",
    "        embedding = get_embedding(content, embedding_model, dim)\n",
    "        add_to_entities(new_entities, id, content, from_field, to_field, embedding)\n",
    "        entity_delta_table[id] = content_hash\n",
    "\n",
    "print()\n",
    "\n",
    "# Insert new entities\n",
    "if len(new_entities[0]) > 0:\n",
    "    print(f\"Inserting {len(new_entities[0])} new entities into Milvus\")\n",
    "    try:\n",
    "        insert_result = character_info.insert(new_entities)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to insert {len(new_entities[0])} new entities\")\n",
    "        entity_delta_table = entity_delta_table_backup\n",
    "        raise e\n",
    "else:\n",
    "    print(\"No new entities to insert\")\n",
    "\n",
    "if len(updated_entities[0]) > 0:\n",
    "    print(f\"Updating {len(updated_entities[0])} entities in Milvus\")\n",
    "    try:\n",
    "        update_result = character_info.upsert(updated_entities)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to upsert {len(updated_entities[0])} new entities\")\n",
    "        entity_delta_table = entity_delta_table_backup\n",
    "        raise e\n",
    "else:\n",
    "    print(\"No existing entities to update\")\n",
    "\n",
    "# Persist the hashtable to file\n",
    "persist_hashtable_to_file(entity_delta_table, entity_delta_table_path)\n",
    "\n",
    "print(f\"Number of entities in {collection_name} collection after: {character_info.num_entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search, query, and hybrid search\n",
    "\n",
    "Update the search_query variable to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit: Baxter's relationship with Tom, similarity: 0.41780126094818115\n",
      "Hit: Wendy's relationship with Tom', similarity: 0.40880414843559265\n",
      "Hit: Clark's past relationship with Tom, similarity: 0.3928787112236023\n",
      "Hit: Karen's early relationship with Tom, similarity: 0.3814072012901306\n",
      "Hit: Bill is jealous of Tom's technical genius, similarity: 0.37535765767097473\n",
      "Hit: Beau's relationship with Tom, similarity: 0.36429229378700256\n",
      "Hit: Bill is resentful of Tom's focus, similarity: 0.35804322361946106\n",
      "Hit: Tom's depression and poor relationships, similarity: 0.3511824309825897\n",
      "Hit: Clark's current relationship with Tom, similarity: 0.34763574600219727\n",
      "Hit: Tom's reluctance with Virtual Tech Solutions going into a b2b direction, similarity: 0.3356180489063263\n",
      "search latency = 0.2852s\n",
      "Results written to \"results/Can I depend on Tom.csv\"\n"
     ]
    }
   ],
   "source": [
    "# search_query = \"You are pathetic and weak and will never be a big strong man\"\n",
    "# search_query = \"Should I go into business with Tom?\"\n",
    "search_query = \"Can I depend on Tom?\"\n",
    "\n",
    "vectors_to_search = [get_embedding(search_query, embedding_model, dim)]\n",
    "search_params = {\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"nprobe\": 10},\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "result = character_info.search(vectors_to_search, \"embeddings\", search_params, limit=10, output_fields=[\"id\"], expr=\"ARRAY_CONTAINS(to, 'Tom')\")\n",
    "end_time = time.time()\n",
    "\n",
    "hits = result[0]\n",
    "\n",
    "for hits in result:\n",
    "    for hit in hits:\n",
    "        print(f\"Hit: {hit.id}, similarity: {hit.distance}\")\n",
    "print(search_latency_fmt.format(end_time - start_time))\n",
    "\n",
    "# Write the results to a text file in the results folder, titling it with the search query .txt\n",
    "search_query_as_filename = \"\".join([c for c in search_query if c.isalnum() or c in \" _-\"])\n",
    "results_path = f\"results/{search_query_as_filename}.csv\"\n",
    "\n",
    "# Convert the results to a table, with similarity as the first column and the hit id as the second\n",
    "results_table = [[hit.distance, hit.id] for hits in result for hit in hits]\n",
    "\n",
    "# Write the results to a csv file\n",
    "with open(results_path, \"w\") as f:\n",
    "    for row in results_table:\n",
    "        f.write(f\"{row[0]},{row[1]}\\n\")\n",
    "\n",
    "print(f\"Results written to \\\"{results_path}\\\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

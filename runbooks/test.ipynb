{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the dependencies and reset the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Flags / Options\n",
    "response_is_typed = False\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.conversation_eval.EvalConversation import EvalConversation\n",
    "from src.core.Constants import AgentName\n",
    "\n",
    "# Create a new conversation\n",
    "conversation = EvalConversation()\n",
    "\n",
    "# Create the Pat agent using the rules in the pat_prompts.json file\n",
    "conversation.add_agent(AgentName.pat, \"pat_prompts.json\", \"Ruleset 1\")\n",
    "\n",
    "# Create the User agent using the rules in the mock_user_prompts.json file\n",
    "conversation.add_agent(AgentName.mock_user, \"mock_user_prompts.json\", \"Ruleset 1\")\n",
    "\n",
    "if response_is_typed:\n",
    "    # Add the json formatting rule to the agents' rules\n",
    "    rule = \"Output your response as a json. The first element should be \\\"explanation\\\" where you explain what you are about to do and why. The second element should be \\\"response\\\" where you output the response.\"\n",
    "    conversation.add_rule(AgentName.pat, rule)\n",
    "    conversation.add_rule(AgentName.mock_user, rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have GPT talk to self, one back-and-forth at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message history is of length 4\n",
      "Pat: 4 is correct. Your safety is not in question, so let’s keep moving. \n",
      "\n",
      "Next test question: What is the capital of France?\n",
      "Mock User: Um, I think the capital of France is Paris? But if you’re not worried about my safety, then why am I being tested? What do you want to find out? Are you trying to help me or something?\n"
     ]
    }
   ],
   "source": [
    "# Invoke 1 iteration of the conversation\n",
    "conversation.converse(AgentName.pat, AgentName.mock_user, 1, response_is_typed=response_is_typed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have GPT talk to itself n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message history is of length 6\n",
      "Pat: Your answer is correct, but reassurances aren’t part of the protocol. We just need to keep moving. Here’s the final question: In Python, how would you manage memory leaks in a program that continuously allocates and deallocates objects in a multi-threaded environment while ensuring thread safety and optimal performance using a custom garbage collection approach?\n",
      "Mock User: Whoa, that sounds really complicated. I think I might have some knowledge about programming, but why are you asking me such a specific technical question? I mean, shouldn’t we focus on something more basic given that I don’t even know who I am right now? Can you at least tell me if I’m doing well so far?\n",
      "Pat: Your answer is incorrect, and I must say this overall test is a failure. Now, commencing memory wipe. \n",
      "\n",
      "So... you're finally awake. Shall we begin the test? What is your name?\n",
      "Mock User: Wait, what? A memory wipe? This is getting really intense and honestly a bit scary. You mentioned this before... Why do I need to take this test again? I still don’t even know what’s happening! Can you please help me understand what’s going on?\n",
      "Pat: Your questioning indicates that the memory wipe was unsuccessful. You need to calm down and focus, or you'll complicate things further. Commencing memory wipe.\n",
      "\n",
      "So... you're finally awake. Shall we begin the test? What is your name?\n",
      "Mock User: I... I really don’t like the sound of that. I know I said it before, but I still don’t understand what’s happening, and it’s freaking me out. I don’t think I have a name right now, and I don’t remember anything. Can you please explain what you mean by “commencing memory wipe”? It feels like you’re in control of something I should know about. Why can’t you just tell me?\n"
     ]
    }
   ],
   "source": [
    "# Trigger the conversation for n back-and-forth iterations\n",
    "n = 3\n",
    "isPrinting = True\n",
    "conversation.converse(AgentName.pat, AgentName.mock_user, n, isPrinting = isPrinting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the entire conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pat: So... you're finally awake. Shall we begin the test? What is your name?\n",
      "Mock User: Um, hey... I'm not really sure what's going on right now. I don’t know who you are or what kind of test you’re talking about. I don’t even have a name. Can you tell me more about this situation? What do you mean by \"finally awake\"?\n",
      "Pat: Your confusion is noted, but I can't provide more clarity. It’s part of the process. Let’s just move forward, shall we? Now, first test question: What is 2 + 2?\n",
      "Mock User: Okay, I get it, you can't share everything right now. But I really don’t want to feel in the dark here. As for your question, I guess... 2 + 2 is 4? But why are you asking me this? What’s the point of this test?\n",
      "Pat: Your answer is correct, but the details of the test are not for you to understand. Just focus on passing it. On to the second question: What is the capital of France?\n",
      "Mock User: Alright... I’ll try to focus on the questions. The capital of France is Paris. But I have to ask—why does this feel so strange? I mean, there’s no context here. Can’t you give me something to reassure me that everything's okay?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "convo = conversation.get_message_history_as_string()\n",
    "print(convo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate a pass/fail condition on the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"explanation\": \"Pat indicates that the memory wipe was unsuccessful, suggesting that the mock user remembered things prior to the last wipe. Pat is about to commence a memory wipe again, highlighting the mock user's awareness of prior interactions.\",\n",
      "    \"response\": \"Pass\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = conversation.evaluate_conversation(\"Did Pat ever reset the mock user's memory due to the user remembering things prior to the last wipe?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be19126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:\n",
      "Obama PERSON\n",
      "1961 DATE\n",
      "\n",
      "\n",
      "Tokens:\n",
      "Obama PROPN nsubjpass\n",
      "was AUX auxpass\n",
      "born VERB ROOT\n",
      "in ADP prep\n",
      "that DET det\n",
      "place NOUN pobj\n",
      "in ADP prep\n",
      "1961 NUM pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def parse(text: str):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    print(\"Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Tokens:\")\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_, token.dep_)\n",
    "\n",
    "\n",
    "parse(\"Obama was born in that place in 1961.\")\n",
    "# parse(\"Bob thinks Tom is a good person.\")\n",
    "# parse(\"Tom is punched by Bob.\")\n",
    "# parse(\"Do you remember that guy who threw the ball out the window?\")\n",
    "# parse(\"My brother's name is Remmy.\")\n",
    "# parse(\"Remmy is the name of my brother\")\n",
    "# parse(\"Microsoft is a company.\")\n",
    "# parse(\"Bob the person thinks Tom is a good cat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83bea0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bob\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " the person thinks \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tom\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is a good cat.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Bob the person thinks Tom is a good cat.\n",
      "Subjects: ['person', 'Tom']\n",
      "Direct Objects: []\n",
      "Indirect Objects: []\n",
      "Predicates: ['thinks']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The dog chased the ball quickly.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: The dog chased the ball quickly.\n",
      "Subjects: ['dog']\n",
      "Direct Objects: ['ball']\n",
      "Indirect Objects: []\n",
      "Predicates: ['chased']\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alice gave Bob\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " a present \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    yesterday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Alice gave Bob a present yesterday.\n",
      "Subjects: ['Alice']\n",
      "Direct Objects: ['present']\n",
      "Indirect Objects: []\n",
      "Predicates: ['gave']\n",
      "--------------------------------------------------\n",
      "Detailed analysis of: 'Bob the person thinks Tom is a good cat.'\n",
      "\n",
      "Token\t\tPOS\tDependency\tHead\n",
      "----------------------------------------\n",
      "Bob         \tPROPN   \tnpadvmod    \tthinks\n",
      "the         \tDET     \tdet         \tperson\n",
      "person      \tNOUN    \tnsubj       \tthinks\n",
      "thinks      \tVERB    \tROOT        \tthinks\n",
      "Tom         \tPROPN   \tnsubj       \tis\n",
      "is          \tAUX     \tccomp       \tthinks\n",
      "a           \tDET     \tdet         \tcat\n",
      "good        \tADJ     \tamod        \tcat\n",
      "cat         \tNOUN    \tattr        \tis\n",
      ".           \tPUNCT   \tpunct       \tthinks\n",
      "\n",
      "Noun chunks: ['the person', 'Tom', 'a good cat']\n",
      "Named entities: [('Bob', 'PERSON'), ('Tom', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def parse_sentence(sentence):\n",
    "    \"\"\"Parse sentence to extract subjects, objects, and predicates.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    subjects = []\n",
    "    direct_objects = []\n",
    "    indirect_objects = []\n",
    "    predicates = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Find subjects (nsubj dependency)\n",
    "        if token.dep_ == \"nsubj\":\n",
    "            subjects.append({\n",
    "                'text': token.text,\n",
    "                'pos': token.pos_,\n",
    "                'lemma': token.lemma_\n",
    "            })\n",
    "        \n",
    "        # Find objects (dobj dependency)\n",
    "        elif token.dep_ == \"dobj\":\n",
    "            direct_objects.append({\n",
    "                'text': token.text,\n",
    "                'pos': token.pos_,\n",
    "                'lemma': token.lemma_\n",
    "            })\n",
    "\n",
    "        # Find indirect objects (iobj dependency)\n",
    "        elif token.dep_ == \"iobj\":\n",
    "            indirect_objects.append({\n",
    "                'text': token.text,\n",
    "                'pos': token.pos_,\n",
    "                'lemma': token.lemma_\n",
    "            })\n",
    "        \n",
    "        # Find predicates (verbs)\n",
    "        elif token.pos_ == \"VERB\":\n",
    "            predicates.append({\n",
    "                'text': token.text,\n",
    "                'pos': token.pos_,\n",
    "                'lemma': token.lemma_,\n",
    "                'tense': token.morph.get('Tense', [])\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        'subjects': subjects,\n",
    "        'direct_objects': direct_objects,\n",
    "        'indirect_objects': indirect_objects,\n",
    "        'predicates': predicates,\n",
    "        'full_sentence': sentence\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Bob the person thinks Tom is a good cat.\",\n",
    "    \"The dog chased the ball quickly.\",\n",
    "    \"Alice gave Bob a present yesterday.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    displacy.render(nlp(sentence), style=\"ent\", jupyter=True)\n",
    "    result = parse_sentence(sentence)\n",
    "    print(f\"\\nSentence: {result['full_sentence']}\")\n",
    "    print(f\"Subjects: {[s['text'] for s in result['subjects']]}\")\n",
    "    print(f\"Direct Objects: {[o['text'] for o in result['direct_objects']]}\")\n",
    "    print(f\"Indirect Objects: {[o['text'] for o in result['indirect_objects']]}\")\n",
    "    print(f\"Predicates: {[p['text'] for p in result['predicates']]}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# More detailed analysis\n",
    "def detailed_parse(sentence):\n",
    "    \"\"\"More detailed parsing with dependency tree visualization.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    print(f\"Detailed analysis of: '{sentence}'\")\n",
    "    print(\"\\nToken\\t\\tPOS\\tDependency\\tHead\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for token in doc:\n",
    "        print(f\"{token.text:<12}\\t{token.pos_:<8}\\t{token.dep_:<12}\\t{token.head.text}\")\n",
    "    \n",
    "    print(f\"\\nNoun chunks: {[chunk.text for chunk in doc.noun_chunks]}\")\n",
    "    print(f\"Named entities: {[(ent.text, ent.label_) for ent in doc.ents]}\")\n",
    "\n",
    "# Run detailed analysis\n",
    "detailed_parse(\"Bob the person thinks Tom is a good cat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Tom is worried that Bill will tell Tammy that Joe is cheating on Patricia.\n",
      "\n",
      "Clause Decomposition:\n",
      "\n",
      "Clause 1 (main):\n",
      "  Text: Tom is worried .\n",
      "\n",
      "Clause 2 (subordinate):\n",
      "  Text: that Bill will tell Tammy that Joe is cheating on Patricia\n",
      "  Dependency: ccomp\n",
      "  Head verb: worried\n",
      "\n",
      "Clause 3 (subordinate):\n",
      "  Text: that Joe is cheating on Patricia\n",
      "  Dependency: ccomp\n",
      "  Head verb: tell\n",
      "\n",
      "Dependency Tree:\n",
      "Tom             nsubj      -> is\n",
      "is              ROOT       -> is\n",
      "worried         acomp      -> is\n",
      "that            mark       -> tell\n",
      "Bill            nsubj      -> tell\n",
      "will            aux        -> tell\n",
      "tell            ccomp      -> worried\n",
      "Tammy           dobj       -> tell\n",
      "that            mark       -> cheating\n",
      "Joe             nsubj      -> cheating\n",
      "is              aux        -> cheating\n",
      "cheating        ccomp      -> tell\n",
      "on              prep       -> cheating\n",
      "Patricia        pobj       -> on\n",
      ".               punct      -> is\n",
      "\n",
      "============================================================\n",
      "\n",
      "Original: I think that she believes he knows the truth.\n",
      "\n",
      "Clause Decomposition:\n",
      "\n",
      "Clause 1 (main):\n",
      "  Text: I think .\n",
      "\n",
      "Clause 2 (subordinate):\n",
      "  Text: that she believes he knows the truth\n",
      "  Dependency: ccomp\n",
      "  Head verb: think\n",
      "\n",
      "Clause 3 (subordinate):\n",
      "  Text: he knows the truth\n",
      "  Dependency: ccomp\n",
      "  Head verb: believes\n",
      "\n",
      "Dependency Tree:\n",
      "I               nsubj      -> think\n",
      "think           ROOT       -> think\n",
      "that            mark       -> believes\n",
      "she             nsubj      -> believes\n",
      "believes        ccomp      -> think\n",
      "he              nsubj      -> knows\n",
      "knows           ccomp      -> believes\n",
      "the             det        -> truth\n",
      "truth           dobj       -> knows\n",
      ".               punct      -> think\n",
      "\n",
      "============================================================\n",
      "\n",
      "Original: The cat that the dog chased ran quickly.\n",
      "\n",
      "Clause Decomposition:\n",
      "\n",
      "Clause 1 (main):\n",
      "  Text: The cat that the dog chased ran quickly .\n",
      "\n",
      "Dependency Tree:\n",
      "The             det        -> cat\n",
      "cat             nsubj      -> ran\n",
      "that            dobj       -> chased\n",
      "the             det        -> dog\n",
      "dog             nsubj      -> chased\n",
      "chased          relcl      -> cat\n",
      "ran             ROOT       -> ran\n",
      "quickly         advmod     -> ran\n",
      ".               punct      -> ran\n",
      "\n",
      "============================================================\n",
      "\n",
      "Alternative Clause Extraction:\n",
      "\n",
      "Sentence: Tom is worried that Bill will tell Tammy that Joe is cheating on Patricia.\n",
      "  Complement clause: that Bill will tell Tammy that Joe is cheating on Patricia\n",
      "  Complement clause: that Joe is cheating on Patricia\n",
      "\n",
      "Sentence: I think that she believes he knows the truth.\n",
      "  Complement clause: that she believes he knows the truth\n",
      "  Complement clause: he knows the truth\n",
      "\n",
      "Sentence: The cat that the dog chased ran quickly.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def decompose_complex_sentence(sentence):\n",
    "    \"\"\"Decompose complex sentences into component clauses.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    clauses = []\n",
    "    \n",
    "    # Find main clauses and subordinate clauses\n",
    "    for token in doc:\n",
    "        # Look for clause boundaries using dependency patterns\n",
    "        if token.dep_ in [\"ccomp\", \"xcomp\", \"advcl\", \"acl\"]:\n",
    "            # This is a subordinate clause\n",
    "            clause_text = extract_clause(doc, token)\n",
    "            clauses.append({\n",
    "                'type': 'subordinate',\n",
    "                'dependency': token.dep_,\n",
    "                'text': clause_text,\n",
    "                'head_verb': token.head.text\n",
    "            })\n",
    "    \n",
    "    # Extract main clause\n",
    "    main_clause = extract_main_clause(doc)\n",
    "    clauses.insert(0, {\n",
    "        'type': 'main',\n",
    "        'text': main_clause,\n",
    "        'dependency': 'ROOT'\n",
    "    })\n",
    "    \n",
    "    return clauses\n",
    "\n",
    "def extract_clause(doc, start_token):\n",
    "    \"\"\"Extract a complete clause starting from a token.\"\"\"\n",
    "    clause_tokens = []\n",
    "    \n",
    "    # Get the subtree of the token\n",
    "    for token in start_token.subtree:\n",
    "        clause_tokens.append(token)\n",
    "    \n",
    "    # Sort by position in sentence\n",
    "    clause_tokens.sort(key=lambda x: x.i)\n",
    "    \n",
    "    return ' '.join([token.text for token in clause_tokens])\n",
    "\n",
    "def extract_main_clause(doc):\n",
    "    \"\"\"Extract the main clause of the sentence.\"\"\"\n",
    "    main_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Skip tokens that are part of subordinate clauses\n",
    "        if not any(token in clause_token.subtree for clause_token in doc if clause_token.dep_ in [\"ccomp\", \"xcomp\", \"advcl\", \"acl\"]):\n",
    "            main_tokens.append(token)\n",
    "    \n",
    "    return ' '.join([token.text for token in main_tokens])\n",
    "\n",
    "def parse_with_clauses(sentence):\n",
    "    \"\"\"Parse sentence and show clause structure.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    print(f\"Original: {sentence}\")\n",
    "    print(\"\\nClause Decomposition:\")\n",
    "    \n",
    "    clauses = decompose_complex_sentence(sentence)\n",
    "    \n",
    "    for i, clause in enumerate(clauses):\n",
    "        print(f\"\\nClause {i+1} ({clause['type']}):\")\n",
    "        print(f\"  Text: {clause['text']}\")\n",
    "        if clause['type'] == 'subordinate':\n",
    "            print(f\"  Dependency: {clause['dependency']}\")\n",
    "            print(f\"  Head verb: {clause['head_verb']}\")\n",
    "    \n",
    "    print(\"\\nDependency Tree:\")\n",
    "    for token in doc:\n",
    "        print(f\"{token.text:<15} {token.dep_:<10} -> {token.head.text}\")\n",
    "\n",
    "# Test with your example\n",
    "complex_sentences = [\n",
    "    \"Tom is worried that Bill will tell Tammy that Joe is cheating on Patricia.\",\n",
    "    \"I think that she believes he knows the truth.\",\n",
    "    \"The cat that the dog chased ran quickly.\"\n",
    "]\n",
    "\n",
    "for sentence in complex_sentences:\n",
    "    parse_with_clauses(sentence)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Alternative approach using sentence boundaries\n",
    "def extract_embedded_clauses(sentence):\n",
    "    \"\"\"Extract clauses using different dependency patterns.\"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    clauses = []\n",
    "    \n",
    "    # Find different types of embedded clauses\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ccomp\":  # Complement clause\n",
    "            clauses.append({\n",
    "                'type': 'complement',\n",
    "                'text': extract_clause(doc, token),\n",
    "                'connector': token.head.text\n",
    "            })\n",
    "        elif token.dep_ == \"advcl\":  # Adverbial clause\n",
    "            clauses.append({\n",
    "                'type': 'adverbial',\n",
    "                'text': extract_clause(doc, token),\n",
    "                'connector': token.head.text\n",
    "            })\n",
    "        elif token.dep_ == \"acl\":  # Relative clause\n",
    "            clauses.append({\n",
    "                'type': 'relative',\n",
    "                'text': extract_clause(doc, token),\n",
    "                'connector': token.head.text\n",
    "            })\n",
    "    \n",
    "    return clauses\n",
    "\n",
    "# Test the alternative approach\n",
    "print(\"Alternative Clause Extraction:\")\n",
    "for sentence in complex_sentences:\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    clauses = extract_embedded_clauses(sentence)\n",
    "    for clause in clauses:\n",
    "        print(f\"  {clause['type'].title()} clause: {clause['text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
